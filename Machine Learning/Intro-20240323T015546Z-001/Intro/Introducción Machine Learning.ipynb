{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contenido\n",
    "\n",
    "- [¿Qué es Ciencia de datos?](#¿Qué-es-Ciencia-de-datos?)\n",
    "- [¿Qué son las Ciencias de la Computación?](#¿Qué-son-las-Ciencias-de-la-Computación?)\n",
    "- [¿Qué es la inteligencia artificial?](#¿Qué-es-la-inteligencia-artificial?)\n",
    "- [¿Qué es Machine Learning?](#¿Qué-es-Machine-Learning?)\n",
    "    - [Aprendizaje supervisado](#Aprendizaje-supervisado)\n",
    "        - [Naive Bayes](#Naive-Bayes)\n",
    "        - [Regresión logística](#Regresión-logística)\n",
    "        - [Regresión lineal](#Regresión-lineal)\n",
    "        - [Árboles de Decisión](#Árboles-de-Decisión)\n",
    "        - [Bosques Aleatorios](#Bosques-Aleatorios)\n",
    "        - [KNN](#KNN)\n",
    "    - [Aprendizaje No Supervisado](#Aprendizaje-No-Supervisado)\n",
    "        - [Clustering](#Clustering)\n",
    "    - [Deep Learning](#Deep-Learning)\n",
    "        - [Redes Neuronales](#Redes-Neuronales)\n",
    "        - [Aprendizaje Reforzado](#Aprendizaje-Reforzado)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ¿Qué es Ciencia de datos?\n",
    "<hr>\n",
    "\n",
    "\n",
    "La ciencia de datos se encarga de estudiar de dónde viene la información, qué representa y cómo se puede convertir en un recurso valioso en la creación de negocios y estrategias. Para ello, busca extraer grandes cantidades de datos para identificar patrones para ayudar a una organización a controlar los costes, aumentar la eficiencia, reconocer nuevas oportunidades de mercado y aumentar la ventaja competitiva de la organización.\n",
    "\n",
    "\n",
    "\n",
    "<img src=\"Data_Science_VD.png\">\n",
    "\n",
    "\n",
    "Cada una de estas habilidades por separado es naturalmente interdiciplinaria y hay que tener que si se combina con solo una de estas no son ciencia de datos.\n",
    "\n",
    "- Para bien o para mal, los datos son una mercancía que se comercializa electrónicamente; por lo tanto, para estar en este mercado es necesario hablar hacker. Sin embargo, esto no requiere una formación en informática; de hecho, muchos de los piratas informáticos más impresionantes que he conocido nunca tomaron un solo curso de informática. Ser capaz de manipular archivos de texto en la línea de comandos, comprender operaciones vectorizadas, pensar algorítmicamente; estas son las habilidades de piratería que lo convierten en un pirata informático exitoso.\n",
    "\n",
    "- Una vez que haya adquirido y limpiado los datos, el siguiente paso es extraer información de ellos. Para hacer esto, debe aplicar métodos matemáticos y estadísticos apropiados, lo que requiere al menos una familiaridad básica con estas herramientas. Esto no quiere decir que un doctorado en estadística requiera ser un científico de datos competente, pero sí requiere saber qué es una regresión por mínimos cuadrados ordinarios y cómo interpretarla.\n",
    "\n",
    "- En la tercera pieza crítica, sustancia, es donde mis pensamientos sobre la ciencia de datos divergen de la mayor parte de lo que ya se ha escrito sobre el tema. Para mí, los datos más las matemáticas y las estadísticas solo te brindan aprendizaje automático, lo cual es genial si eso es lo que te interesa, pero no si estás haciendo ciencia de datos. La ciencia se trata de descubrir y construir conocimiento, lo que requiere algunas preguntas motivadoras sobre el mundo e hipótesis que se pueden llevar a los datos y probar con métodos estadísticos. Por otro lado, la experiencia sustantiva más el conocimiento de matemáticas y estadística es donde cae la mayoría de los investigadores tradicionales. Los investigadores de nivel de doctorado dedican la mayor parte de su tiempo a adquirir experiencia en estas áreas, pero muy poco tiempo a aprender sobre tecnología. Parte de esto es la cultura académica, que no recompensa a los investigadores por comprender la tecnología. Dicho esto, he conocido a muchos jóvenes académicos y estudiantes de posgrado que están ansiosos por romper esa tradición.\n",
    "\n",
    "- Por último, unas palabras sobre las habilidades de piratería informática más la zona de peligro de la experiencia sustancial. Aquí es donde coloco a las personas que \"saben lo suficiente para ser peligrosas\" y es el área más problemática del diagrama. En esta área, las personas que son perfectamente capaces de extraer y estructurar datos, probablemente relacionados con un campo del que conocen bastante, y probablemente incluso sepan suficiente R para ejecutar una regresión lineal e informar los coeficientes; pero carecen de comprensión de lo que significan esos coeficientes. Es de esta parte del diagrama de donde emana la frase \"mentiras, malditas mentiras y estadísticas\", porque ya sea por ignorancia o malicia, esta superposición de habilidades da a las personas la capacidad de crear lo que parece ser un análisis legítimo sin comprender cómo llegaron allí o lo que han creado. Afortunadamente, se requiere una ignorancia casi deliberada para adquirir habilidades de piratería y experiencia sustancial sin aprender también algunas matemáticas y estadísticas en el camino. Como tal, la zona de peligro está escasamente poblada, sin embargo, no se necesitan muchos para producir mucho daño."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Regresar al contenido](#Contenido)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ¿Qué son las Ciencias de la Computación?\n",
    "\n",
    "\n",
    "Las ciencias de la computación es el estudio de las computadoras y los sistemas computacionales. Un científico computacional se ocupa principalmente de sistemas de softwere y hardwere; esto incluye su teoría, diseño, desarrollo y aplicación.\n",
    "\n",
    "Aunque saber programar es fundamental para el estudio de las ciencias de la computación, es solo un elemento del campo. Los computer scientis diseñan y analizan algoritmos para resolver programas y estudiar el rendimiento del hardware y software de las computadoras. Los problemas con los que se encuentran los científicos informáticos van desde lo abstracto (determinar qué problemas se pueden resolver con las computadoras y la complejidad de los algoritmos que los resuelven) hasta lo tangible: diseñar aplicaciones que funcionen bien en dispositivos portátiles, que sean fáciles de usar y que mantienen las medidas de seguridad.\n",
    "\n",
    "<hr>\n",
    "\n",
    "- Diseño del funcionamiento de procesadores.\n",
    "- Arquitectura de softwere.\n",
    "- Desarrollo de lenguajes de programación.\n",
    "- Seguridad Informatica.\n",
    "- <p style=\"color:red;\"> Inteligencia artificial </p>\n",
    "\n",
    "\n",
    "<hr>\n",
    "\n",
    "### Arquitectura de las computadoras\n",
    "\n",
    "La arquitectura de computadores es el diseño conceptual y la estructura operacional fundamental de un sistema cómputo. Se centra en gran medida de la manera en que la unidad central de procesamiento (CPU) realiza internamente y accede a las direcciones en la memoria. \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Análisis de rendimiento de computadoras\n",
    "\n",
    "Análisis de rendimiento del equipo es el estudio del trabajo que fluye a través de los equipos con el objetivo general de mejora de rendimiento y control de tiempo de respuesta, utilizando los recursos de manera eficiente, la eliminación de los cuellos de botella, y la predicción de rendimiento bajo cargas máximas previstas.\n",
    "\n",
    "\n",
    "### Computo Científico\n",
    "\n",
    "El computo científico es el campo de estudio que trata con la construcción de modelos matemáticos y técnicas de análisis cuantitativos, así como el uso de computadoras para analizar y resolver problemas científicos. En el uso práctico, es típicamente la aplicación de simulación por ordenador y otras formas de cálculo a los problemas en diversas disciplinas científicas.\n",
    "\n",
    "\n",
    "### Bases de datos\n",
    "\n",
    "Una base de datos tiene la intención de organizar, almacenar y recuperar grandes cantidades de datos de forma sencilla. Bases de datos digitales se gestionan mediante sistemas de gestión de base de datos para almacenar, crear, mantener y consultar los datos, a través de modelos de bases de datos y lenguajes de consulta. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Regresar al contenido](#Contenido)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ¿Qué es la inteligencia artificial?\n",
    "\n",
    "No hay una definición universalmente acordada. A Alan Turing generalmente se le atribuye el origen del concepto cuando especuló en 1950 acerca de las “máquinas pensantes” que podrían razonar al nivel de un ser humano. Turing fue seguido unos años más tarde por John McCarthy, quien utilizó por primera vez el término \"inteligencia artificial\" para denotar máquinas que podían pensar de forma autónoma. Describió el umbral como \"conseguir que una computadora haga cosas que, cuando las hacen las personas, se dice que involucran inteligencia\".\n",
    "\n",
    "\n",
    "El término inteligencia artificial se aplica cuando una máquina imita las funciones _cognitivas_ que los humanos asocian con otras mentes humanas. \n",
    "\n",
    "- Tomamos decisiones tomando en cuenta las experiencias que hemos vivido.\n",
    "- Aprendemos día a día sobre las experiencias y errores vividos.\n",
    "- Resolver problemas.\n",
    "- Percibir e interactuar con su entorno.\n",
    "\n",
    "Hay dos tipos de inteligencia artificial, la _inteligencia artificial especifica_ que es aquella que se enfoca en que la maquina haga una tarea muy especifica muy bien, mejor quiza que los humanos, como por ejemplo:\n",
    "\n",
    "- Comunicarse usando lenguaje natural, de forma verbal o escrita.\n",
    "- Detectar matriculas de carros en tiempo real en videos de vigilancia.\n",
    "- Jugar al ajedrez.\n",
    "\n",
    "El otro tipo de inteligencia artificial es la _inteligencia artificial general_ que es la idea utópica de tener una inteligencia artificial que imite el comportamiento humano por completo.\n",
    "\n",
    "\n",
    "\n",
    "<img src=\"ultron.jpg\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import YouTubeVideo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytl = \"fn3KWM1kuAw\"\n",
    "ytv = YouTubeVideo(ytl)\n",
    "display(ytv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Regresar al contenido](#Contenido)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ¿Qué es Machine Learning?\n",
    "\n",
    "\n",
    "Es la subrama de la inteligencia artificial que permite que las computadoras aprendan y actúen como lo hacen los humanos, mejorando su aprendizaje a lo largo del tiempo de una forma autónoma, alimentándolas con datos e información en forma de observaciones e interacciones con el mundo real.\n",
    "\n",
    "Las computadoras son muy buenas haciendo tareas (cálculos), y nosotros podemos pedirles que hagan esas tareas por nosotros, eso eslo que llamamos programar, escribir una serie de instrucciones explicitas que la computadora va a realizar por nosotros. En el machine learning esta estructura de trabajo se va a modificar un poco, ya que trabajaremos con los datos y con los resultados que estos ya produjeron, y buscaremos un patron subyacente.\n",
    "\n",
    "Machine learning ofrece una manera eficiente de capturar el conocimiento mediante la información contenida en los datos, para mejorar de forma gradual el rendimiento de modelos predictivos y tomar decisiones basadas en dichos datos. Se ha convertido en una tecnología con una amplia presencia, y actualmente está presente en: filtros anti-spam (Naive Bayes) para correo electrónico, conducción automática de vehículos o reconocimiento de voz e imágenes.\n",
    "\n",
    "- Computadoras con la habilidad de aprender sin ser explícitamente programadas.\n",
    "- Recibe un conjunto de datos y aprende de ellos.\n",
    "- Los analiza, reconoce patrones, y hace la predicción."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytl = \"QcCjmWwEUgg?t=78\"\n",
    "ytv = YouTubeVideo(ytl)\n",
    "display(ytv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Juguemos un poco](https://teachablemachine.withgoogle.com)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hay varios tipos de algoritmos de Machine learning:\n",
    "\n",
    "- Supervisados\n",
    "- No supervisados\n",
    "- Aprendizaje Reforzado (Deep learning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Juguemos un poco más](https://ml-playground.com/#)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Regresar al contenido](#Contenido)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aprendizaje supervisado\n",
    "\n",
    "Se refiere a un tipo de modelos de Machine Learning que se entrenan con un conjunto de ejemplos en los que los resultados de salida son conocidos. Los modelos aprenden de esos resultados conocidos y realizan ajustes en sus parámetros interiores para adaptarse a los datos de entrada. Una vez el modelo es entrenado adecuadamente, y los parámetros internos son coherentes con los datos de entrada y los resultados de la batería de datos de entrenamiento, el modelo podrá realizar predicciones adecuadas ante nuevos datos no procesados previamente.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Regresar al contenido](#Contenido)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clasificación\n",
    "\n",
    "\n",
    "### Naive Bayes\n",
    "\n",
    "En un sentido amplio, los modelos de Naive Bayes son una clase especial de algoritmos de clasificación de Aprendizaje Automático. Se basan en el teorema de Bayes. Estos modelos son llamados algoritmos “Naive”, o “Inocentes” en español. En ellos se asume que las variables predictoras son independientes entre sí. En otras palabras, que la presencia de una cierta característica en un conjunto de datos no está en absoluto relacionada con la presencia de cualquier otra característica.\n",
    "\n",
    "#### Puntos fuertes y débiles de Naive Bayes\n",
    "\n",
    "Los puntos fuertes principales son:\n",
    "\n",
    "- Un manera fácil y rápida de predecir clases, para problemas de clasificación binarios y multiclase.\n",
    "- En los casos en que sea apropiada una presunción de independencia, el algoritmo se comporta mejor que otros modelos de clasificación, incluso con menos datos de entrenamiento.\n",
    "\n",
    "\n",
    "Los puntos débiles principales son:\n",
    "\n",
    "- Aunque son unos clasificadores bastante buenos, los algoritmos Naive Bayes son conocidos por ser pobres estimadores. Por ello, no se deben tomar muy en serio las probabilidades que se obtienen.\n",
    "\n",
    "- La presunción de independencia Naive muy probablemente no reflejará cómo son los datos en el mundo real."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Regresar al contenido](#Contenido)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regresión logística\n",
    "\n",
    "\n",
    "Es un algoritmo de clasificación binario (**solo hay dos clases posibles**), un algoritmo simple y muy utilizado. Debe su nombre al uso de la función logística:\n",
    "\n",
    "\n",
    "$$y = \\frac{1}{1 + e^{-x}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from jupyterthemes import jtplot\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jtplot.style()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (13, 8))\n",
    "\n",
    "x = np.linspace(-10, 10, 1000)\n",
    "y = 1 / (1 + np.exp(-x))\n",
    "\n",
    "ax.plot(x, y)\n",
    "ax.axhline(0.5, color = 'r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si la salida de esta función es mayor que 0.5, podemos clasificar el resultado como **1** o **sí** y si la salida es menor que 0.5 entonces podemos clasificar como **0** o **No**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Regresar al contenido](#Contenido)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regresión\n",
    "\n",
    "Son algoritmos que vamos a utilizar cuando la predicción que queramos realizar sea un valor numérico, como el precio de una casa o el valor de una acción.\n",
    "\n",
    "#### Regresión lineal\n",
    "\n",
    "Dados X e Y, establecemos una línea recta que minimice la distancia (con el método de mínimos cuadrados) entre los puntos de muestra y la línea ajustada. Después, utilizaremos las desviaciones obtenidas en la formación de la línea para predecir nuevos datos de salida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (13, 8))\n",
    "\n",
    "x = np.linspace(0, 5, 1000)\n",
    "y = 3 * x + 2\n",
    "z = 3 * x + 2 + np.random.normal(size = 1000)\n",
    "\n",
    "ax.plot(x, y, color = 'r')\n",
    "ax.scatter(x, z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Regresar al contenido](#Contenido)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Árboles de Decisión\n",
    "\n",
    "Los árboles de decisión son uno de los algoritmos más utilizados para la toma de decisiones en Machine Learning. Un árbol de decisión es un modelo predictivo que divide el espacio de los predictores agrupando observaciones con valores similares para la variable respuesta o dependiente. Un árbol de decisión es un algoritmo supervisado de aprendizaje automático porque para que aprenda el modelo necesitamos una variable dependiente en el conjunto de entrenamiento.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (8, 8))\n",
    "\n",
    "x1 = np.random.random(20) + 5\n",
    "y1 = np.random.random(20) + 4\n",
    "\n",
    "x2 = np.random.random(20) + 4\n",
    "y2 = np.random.random(20) + 4\n",
    "\n",
    "x3 = np.random.random(20) + 5\n",
    "y3 = np.random.random(20) + 5\n",
    "\n",
    "x4 = np.random.random(20) + 4\n",
    "y4 = np.random.random(20) + 5\n",
    "\n",
    "ax.scatter(x1, y1, color = 'g')\n",
    "ax.scatter(x2, y2, color = 'r')\n",
    "ax.scatter(x3, y3, color = 'r')\n",
    "ax.scatter(x4, y4, color = 'r')\n",
    "ax.axvline(5, color = (255 / 255, 199 / 255, 25/255), alpha = 0.7)\n",
    "ax.axhline(5, color = (255 / 255, 199 / 255, 25/255), alpha = 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso nuestro árbol de decisión tiene la siguiente forma:\n",
    "\n",
    "<img src=\"Árbol de Decisión.png\">\n",
    "\n",
    "\n",
    "Veamos un ejemplo con código de Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import export_graphviz\n",
    "import graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#conda install python-graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arbol = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arbol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arbol.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arbol.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_graphviz(arbol, out_file = \"arbol.dot\", class_names = iris.target_names,\n",
    "                feature_names = iris.feature_names, impurity = False, filled = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"arbol.dot\") as f:\n",
    "    dot_graph = f.read()\n",
    "graphviz.Source(dot_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "caract = iris.data.shape[1]\n",
    "plt.barh(range(caract), arbol.feature_importances_)\n",
    "plt.yticks(np.arange(caract), iris.feature_names)\n",
    "plt.xlabel(\"Importancia de las caracteristicas\")\n",
    "plt.ylabel(\"Caracteristicas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Regresar al contenido](#Contenido)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bosques Aleatorios\n",
    "\n",
    "Es un algoritmo de Machine Learning supervisado que se puede usar para tereas de regresión y de clasificación, este crea multiples arboles de decisión y los combina para obtener una predicción más precisa y estable. Se agrega aleatoreidad adicional ya que en lugar de elegir la caracteristica más importante, selecciona la más importante de un subconjunto aleatorio de características. El bosque aleatorio hace esto varias veces para generar varios arboles de decisión y luego promedia los resultados. Entre más arboles genere el bosque, más lento será el algoritmo, en general es un algoritmo rápido de entrenar, pero lento ppara generar predicciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bosque = RandomForestRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bosque.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bosque.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bosque.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bosque.predict(x_test) == y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Regresar al contenido](#Contenido)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN\n",
    "\n",
    "El algoritmo k-Nearest Neighbor es un método que simplemente busca en las observaciones más cercanas a la que se está tratando de predecir y clasifica el punto de interés basado en la mayoría de datos que le rodean. \n",
    "\n",
    "Es un algoritmo supervisado, no paramétrico y basado en instancia, esto quiere decir que nuestro algoritmo no aprende explícitamente un modelo (como por ejemplo en Regresión Logística o árboles de decisión) si no que memoriza las instancias de entrenamiento que son usadas como _base de conocimiento_ para la fase de predicción. Esto quiere decir que este algoritmo puede tener un coste de memoria potencialmente alto, ya que necesita almacenas el conjunto de datos y estos pueden ser muy grandes. y puede ser lento al momento de predecir.\n",
    "\n",
    "\n",
    "Para realizar una predicción el algoritmo sigue los siguientes pasos:\n",
    "\n",
    "- Calcular la distancia entre el ítem a clasificar y el resto de ítems del dataset de entrenamiento.\n",
    "- Seleccionar los _k_ elementos más cercanos (con menor distancia, según la función que se use)\n",
    "- Realizar una _votación de mayoría_ entre los _k_ puntos: los de la clase que _dominen_ decidirán su clasificación final.\n",
    "\n",
    "\n",
    "En este algoritmo _k_ es un hiperparametro, lo que quiere decir que lo define el data scientist al momento de implementar el algoritmo.\n",
    "\n",
    "<img src=\"KNN-Algorithm.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cancer = load_breast_cancer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(cancer.data, cancer.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test == knn.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Regresar al contenido](#Contenido)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aprendizaje No Supervisado\n",
    "\n",
    "En el aprendizaje no supervisado, trataremos con datos sin etiquetar cuya estructura es desconocida. El objetivo será la extracción de información significativa, sin la referencia de variables de salida conocidas, y mediante la exploración de la estructura de dichos datos sin etiquetar.\n",
    "\n",
    "Hay dos categorías principales: agrupamiento y reducción dimensional."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agrupamiento\n",
    "\n",
    "\n",
    "\n",
    "# Clustering\n",
    "\n",
    "El agrupamiento es una técnica exploratoria de análisis de datos, que se usa para organizar información en grupos con significado sin tener conocimiento previo de su estructura. Cada grupo es un conjunto de objetos similares que se diferencia de los objetos de otros grupos. El objetivo es obtener un número de grupos de características similares.\n",
    "\n",
    "Un ejemplo de aplicación de este tipo de algoritmos puede ser para establecer tipos de consumidores en función de sus hábitos de compra, para poder realizar técnicas de marketing efectivas y “personalizadas”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.youtube.com/watch?v=yv2xwnvmbW4\n",
    "ytl = \"yv2xwnvmbW4\"\n",
    "ytv = YouTubeVideo(ytl)\n",
    "display(ytv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Regresar al contenido](#Contenido)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Deep Learning\n",
    "\n",
    "El Deep Learning  es un subcampo de Machine Learning que usa una estructura imita el cerebro humano, con los nodos de neuronas conectadas como una tela de araña. Esta arquitectura permite abordar el análisis de datos de forma no lineal.\n",
    "\n",
    "\n",
    "## Redes Neuronales\n",
    "\n",
    "<hr>\n",
    "\n",
    "### Neuronas\n",
    "\n",
    "La complejidad de estas redes surge de la interacción de muchas partes más simples llamadas _neuronas_. De forma similar a una neurona biológica, estas neuronas tienen conexiones de entrada a través de las cuales recibe estímulos externos, los valores de entrada, con estos valores realizará un cálculo interno y generara un valor de salida.\n",
    "\n",
    "<img src=\"Neurona1.png\" width = 400 height = 400>\n",
    "\n",
    "En este sentido una neurona no es más que una función matemática, en concreto es un _campo escalar_, y va a realizar una suma ponderada de los datos de entrada, esto es a grandes rasgos, hacer una regresión lineal:\n",
    "\n",
    "<img src=\"Neurona2.png\" width = 400 height = 400>\n",
    "\n",
    "$$y = \\frac{1}{1 + e^{-(w_1 x_1 + w_2 x_2 + w_3 x_3)}}$$\n",
    "\n",
    "Veamos un ejemplo en el que queremos predecir si a un estudiante le irá bien en un examen, y vamos a suponer que tenemos dos variables de entrada, ambas binarias. La primera toma el valor 1 si el alumno estudio para su examen y 0 si no, mientras que la segunda toma el valor 1 si el estudiante se alimentó antes del examen y 0 si no, el estudiante solo aprobará el examen (1) si estudio y se alimentó bien antes del examen, es decir tratamos de predecir una variable binaria. Sin embargo, con lo visto hasta ahora la neurona funciona como una regresión lineal, y la regresión lineal no regresa un valor binario, si no uno continuo, para solucionar esto lo que haremos será evaluar el resultado de la regresión lineal y si el valor supera un cierto umbral le asignamos el valor 1 y si es inferior el valor 0, vamos a suponer un umbral de 0 para simplificar los cálculos.\n",
    "\n",
    "$$y = 4E + 5A - 6$$\n",
    "\n",
    "|Estudio|Alimentación|Examen|Y|\n",
    "|:-----:|:----------:|:----:|:-:|\n",
    "|0|0|0|-6|\n",
    "|1|0|0|-2|\n",
    "|0|1|0|-1|\n",
    "|1|1|1|3|\n",
    "\n",
    "- Clasifica y encuentra correlación entre los datos.\n",
    "- Con su conocimiento adquirido sin intervención humana, puede aplicarlo a nuevos datos\n",
    "- Mientras más datos tenga a su disposición más precisa serán sus predicciones.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "x = np.linspace(0, 1)\n",
    "y = (-4/5) * x + (6 / 5)\n",
    "\n",
    "ax.plot(x, y)\n",
    "ax.scatter(1, 1, color = 'g')\n",
    "ax.scatter([0, 0, 1], [0, 1, 0], color = 'r')\n",
    "ax.fill_between(x, y, color = 'r', alpha = 0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La recta de nuestra regresión está separando los puntos de la gráfica en dos puntos diferentes, por lo que podemos entender que estamos buscando aquellos valores de nuestros parámetros, que tracen una frontera entre las dos clases que queremos clasificar. Pero, ¿qué ocurre si nuestros puntos que tratamos de clasificar tienen otra forma?, como esta:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.scatter([1, 0], [1, 0], color = 'r')\n",
    "ax.scatter([0, 1], [1, 0], color = 'g')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso no podemos separar los dos grupos usando una única recta, es decir una única neurona, la solución es sencilla y es usar una neurona adicional así tendríamos dos rectar para realizar la separación:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "x = np.linspace(0, 1)\n",
    "y = (-4/5) * x + (6 / 5)\n",
    "y2 = (-4/5) *x + (3/5)\n",
    "\n",
    "ax.plot(x, y, color = 'b')\n",
    "ax.plot(x, y2, color = 'b')\n",
    "ax.scatter([1, 0], [1, 0], color = 'r')\n",
    "ax.scatter([0, 1], [1, 0], color = 'g')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Regresar al contenido](#Contenido)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### La Red\n",
    "\n",
    "Al combinar varias neuronas podemos formar finalmente una red red neuronal: \n",
    "\n",
    "<img src=\"red neuronal.png\" width = 500 height = 500>\n",
    "\n",
    "Pero con lo que hemos mencionado hasta ahora cada neurona hace una regresión lineal, eso convierte a cada capa de la red en una especie de _transformación lineal_ y entonces una red neuronal no sería más que aplicar una serie de _transformaciones lineales_ una tras otra (una composición de _transformaciones lineales_) lo que equivaldría a solo una _transformación lineal_ es decir: una neurona, nuestra red a colapsado, para evitarlo tenemos que aplicar un factor _no lineal_ y este factor es una **función de activación**, ya hemos visto un ejemplo de función de activación antes, en la regresión logística:\n",
    "\n",
    "$$y = \\frac{1}{1 + e^{-x}}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "x = np.linspace(-10, 10, 1000)\n",
    "y = 1 / (1 + np.exp(-x))\n",
    "\n",
    "ax.plot(x, y)\n",
    "ax.axhline(0.5, color = 'r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta función nos permite hacer lo mismo que teníamos antes, pero añadiendo un factor no lineal. Esta no es la única función de activación, tenemos por ejemplo la función tangente hiperbólica:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "x = np.linspace(-10, 10, 1000)\n",
    "y = np.tanh(x)\n",
    "\n",
    "ax.plot(x, y)\n",
    "ax.axhline(0, color = 'r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y donde esta nuestra función de activación en el ejemplo anterior?\n",
    "\n",
    "\n",
    "<img src=\"Función de activación.jpg\" width = 500 height = 500>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En general hay una familia de diferentes funciones de activación, cada una con sus ventajas y desventajas que dependen del problema que queramos resolver. De esta forma al añadir el factor no lineal cada capa extrae nueva información de los datos, cada capa **profundiza** en ellos, y es por eso que a este tipo de técnicas se les llama **Deep Learning**.\n",
    "\n",
    "\n",
    "<img src=\"red neuronal.png\" width = 500 height = 500>\n",
    "\n",
    "\n",
    "\n",
    "Recordemos que las redes neuronales siguen siendo algoritmos de inteligencia artificial, por lo que esperamos que los parámetros involucrados se ajusten solos, para ello se hacer uso del algoritmo de _back propagation_ para poder calcular el gradiente de nuestra red, y con ello poder usar el descenso del gradiente para el ajuste de los parámetros.\n",
    "\n",
    "<img src=\"parámetros.jpg\" width = 500 height = 500>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "[Juguemos aún más](https://playground.tensorflow.org/#activation=tanh&batchSize=10&dataset=circle&regDataset=reg-plane&learningRate=0.03&regularizationRate=0&noise=0&networkShape=4,2&seed=0.71944&showTestData=false&discretize=false&percTrainData=50&x=true&y=true&xTimesY=false&xSquared=false&ySquared=false&cosX=false&sinX=false&cosY=false&sinY=false&collectStats=false&problem=classification&initZero=false&hideText=false)\n",
    "\n",
    "\n",
    "<img src=\"batalla de los bastardos.jpg\" width = 500 height = 500>\n",
    "\n",
    "\n",
    "<img src=\"función para salvar a John Snow.jpg\" width = 500 height = 500>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Regresar al contenido](#Contenido)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aprendizaje Reforzado\n",
    "\n",
    "El aprendizaje reforzado es una de las ramas más importantes del aprendizaje profundo. El objetivo es construir un modelo con un agente que mejora su rendimiento, basándose en la recompensa obtenida del entorno con cada interacción que se realiza. La recompensa es una medida de lo correcta que ha sido una acción para obtener un objetivo determinado. El agente utiliza esta recompensa para ajustar su comportamiento futuro, con el objetivo de obtener la recompensa máxima.\n",
    "\n",
    "\n",
    "<img src=\"perrito robot.jpg\" width = 500 height = 500>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.youtube.com/watch?v=5SkQuT3kZOc\n",
    "ytl = \"5SkQuT3kZOc\"\n",
    "ytv = YouTubeVideo(ytl)\n",
    "display(ytv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"diagrama de ven.png\" width = 500 height = 500>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
